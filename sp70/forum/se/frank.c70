*****  Computer Select, November 1993  : Articles *****

Journal:    DBMS  March 1993 v6 n3 p57(7)
* Full Text COPYRIGHT M&T Publishing Inc. 1993.
-------------------------------------------------------------------------
Title:     CASE for client/server.
             (includes a related article on various computer-aided
             software engineering methods)
Author:    Frank, Maurice


Abstract:  Computer-aided software engineering (CASE) and client/server
           application development are just beginning to merge.
           Client/server development differs from traditional
           systems-development models supported by CASE tools, but CASE
           vendors are adapting slowly.  The three primary differences
           between client/server and traditional applications are that
           client/server systems distribute parts of an application, the
           front ends are architecturally different from most of their
           predecessors, and the front ends are more varied.  The
           database is responsible for much more than just data storage
           in the client/server model: it handles such tasks as backup,
           recovery, query optimization, and both data and referential
           integrity.  CASE tools must be able to capture the integrity
           controls of SQL-based client/server databases during the
           analysis and design phase.  The advantages of CASE tools for
           database design and the development of integrated CASE (ICASE)
           products are described.
-------------------------------------------------------------------------
Full Text:

INCREASING ALLIANCES AND INTEGRATION TECHNIQUES BETWEEN CASE AND
CLIENT/SERVER VENDORS PROMISES DEVELOPERS A STRONGER ARSENAL OF
DEVELOPMENT TOOLS.

Client/server application development is attracting support from a wide
variety of CASE tool vendors.  While the convergence of these
technologies is still immature, several interesting products and
alliances illustrate different forms of integration.  Client/server
development differs from the traditional systems-development models
supported by CASE tools.  CASE vendors, however, are adapting, but much
more evolution is needed.  DBMS first investigated this topic last year.
(See "Down-sizing with CASE" by R. Lynn Kernighan, DBMS, January 1992.)
This article surveys recent developments.

Developers wishing to use CASE technologies for developing client/server
applications must wrestle with at least three major distinctions between
client/server and traditional applications: Unlike monolithic systems,
client/server systems distribute parts of an application; the front ends
are architecturally different from most of their predecessors; and the
front ends are also far more varied.

These distinctions raise some interesting questions regarding the use of
CASE.  Because developers may design a database without foreknowledge of
all the applications accessing it, should they use different tools for
data and application modeling? Now that the database shares some
processing responsibilities with the application programs, what issues
become more important to database designers? Given the diversity of front
ends, how can process-modeling CASE tools manage the transition from
logical to physical design? How must CASE tools change to keep pace with
newer programming paradigms adopted by front ends? These questions are
not exhaustive.

Client/Server Design

In the client/server model, the database is responsible for much more
than simple data storage.  It handles tasks such as backup, recovery,
query optimization, and both data and referential integrity.  Integrity
is a critical issue for database analysts.  Integrity rules usually
originate as business specifications.

SQL-based client/server databases provide a host of integrity controls.
This logic takes two forms: declarative and procedural.  CASE tools must
be able to capture the full range of integrity specifications during the
analysis and design phase.  Analysts should associate integrity rules and
logic with the database rather than application processes.
Database-resident integrity controls are application independent.  That
is one of the key strengths of client/server architecture.

Declarative integrity rules are part of the SQL Data Definition Language
(DDL).  These statements define PRIMARY KEYS, NOT NULL constraints for
attributes, FOREIGN KEY relationships, and other referential constraints
such as ON DELETE CASCADE.  Domains represent another means to validate
attributes.

Stored procedures and triggers also enforce integrity rules (see "Using
Stored Procedures and Triggers" by Herb Edelstein, DBMS, September 1992).
 These precompiled server-resident programs can handle more complex
business rules because they combine any number of SQL and procedural
statements.  These procedural sublanguages, however, are vendor specific
and vary more than the declarative syntax.

Most CASE tools for relational data modeling capture simple integrity
constraints such as PRIMARY KEYS, FOREIGN KEYS, and NOT NULL constraints
on entity relationship diagrams.  Support for stored procedures and
triggers is new.  More vendors have promised it than have packaged it, at
least as of this writing.  In addition, CASE tools have barely addressed
support for SQL transactions, a major integrity issue in client/server
systems (see "Modeling Transaction Integrity" by Maurice Frank, DBMS,
January 1993).

Until the late 1980s, developers built most traditional applications on
both mainframe and microcomputer platforms using procedural languages
such as COBOL, C, or Xbase for character-based environments.  More
recently, developers have been choosing event-driven Windows GUI tools
over other procedural products for building client/server applications.

CASE tools emerged to aid procedural applications by automating the
structured analysis and design techniques originating in the 1970s.
While upper CASE tools focused on the early phases of the
systems-development life cycle, lower CASE tools addressed code
generation during the later stages.  I-CASE (or integrated CASE) tools
cover the whole spectrum from planning through generation.

Adapting the traditional CASE approach to client/server applications
faces at least two hurdles.  Event-driven GUI applications do not have
the fixed flow of control found in procedural applications.  This means
structure charts and data flow diagrams may not map well to GUI design.
Object-oriented modeling is gaining wider acceptance by developers
designing event-driven applications.  Object models usually elevate the
importance of events and states.  Some CASE tools are embracing object
modeling.  Popkin Systems and Software Inc. (New York, N.Y.), for
example, recently released an object-oriented modeling option for System
Architect.

Developers use modern client/server application-development products such
as PowerBuilder to prototype and deliver a production application.  They
may abbreviate the full life-cycle planning, analysis, and design work.
In this scenario, the application generator absorbs much of the effort
that would have gone into process modeling.  CASE tools may still be more
useful for database modeling or documentation because client/server front
ends often access existing databases.

Another defining characteristics of the client/server world is a diverse
assortment of front ends.  Traditional applications carved out of COBOL
or C for character-based "green screens" share the same fundamental
architecture.  Client/server front-end tools employ many different
programming paradigms.

GUI languages and development products cover a broad spectrum.  Some
require programming, others minimize it.  Some are partially or fully
object-oriented, others are not.  Not all client/server front ends are
graphical.  Even Xbase products such as Clipper develop front ends using
libraries that connect to SQL Server or other DBMSs.

CASE for Database Design

Before CASE tools addressed client/server front-end application
development, they began supporting client/server back-end databases.
Relational database definitions may vary somewhat at a syntactic level,
but the fundamental concepts are much more consistent than front-end
application paradigms.

CASE tools aid the transition from logical modeling to physical
implementation by capturing physical details, such as data types and
lengths of attributes, UNIQUE and NOT NULL constraints, keys, and so
forth, on entity relationship models.  These specifications drive schema
generators that produce script files containing SQL DDL statements.  Many
CASE tools also reverse engineer database definitions out of script files
or the catalog and into the CASE tool.

Most high-end CASE tools originally targeted to DB2 or mainframe Oracle
users now support the most popular client/server DBMS engines, such as
Sybase/Microsoft SQL Server, Oracle Server, and Gupta SQLBase.  Even
relatively inexpensive CASE tools such as Popkin's System Architect and
ERwin/ERX from LogicWorks (Princeton, N.J.) provide these features for
prices in the $2000 range.  EasyCASE Plus from Evergreen CASE Tools Inc.
(Redmond, Wash.) does so for less than $1000.

Schema generation and reverse engineering represent a basic level of CASE
and DBMS integration.  Several CASE vendors are extending their
entity-relation-modeling products to generate stored procedures and
triggers, features unique to client/server DBMSs.  Logic Work experts to
ship ERwin/ERX version 1.2 by early spring 1993, making it one of the
first CASE tools with this form of integrity support.  Several other
vendors, including LBMS Inc., Bachman Information Systems, and Intersolv,
said they plan to add this feature set to their products in upcoming
releases.  Support for stored procedures and triggers will likely become
as common as schema generation and reverse engineering.

ERwin/ERX adds a new dialog to capture trigger definitions.  A trigger is
attached to an entity.  The product bases the default trigger logic on
the relationships the entity participates in and the referential
constraints defined for each relationship.  An entity can have many
triggers.  ERwin/ERX generates trigger syntax specific to several
servers, including Sybase/Microsoft SQL Server, Oracle 7, and DEC's Rdb.
The contents of the trigger dialog change based on the server's
trigger-related features.  ERwin disables the trigger menu option and
dialog for databases that do not support them, such as DB2; see Figure 1.
 (ERwin/ERX also performs schema generation and reverse engineering for
DB2.)

CASE and Front Ends

One of the hallmarks of client/server development is the astonishing
variety of front-end application development tools.  For mainframe
systems, COBOL has mostly been the automatic choice for applications
programming, which facilitated the development of I-CASE products.  The
"I" stands for integrated because these tools integrate upper and lower
CASE functions by generating source code from the CASE design
specifications.

I-CASE becomes economically feasible when a single language monopolizes
almost all application development.  The variety inherent in the
client/server world complicates this level of integration, but vendors
have found at least two strategies to deliver I-CASE for client/server
systems.  One strategy links up with the most popular front ends, while
the other requires vendors to deliver application generators of their
own.

PowerBuilder from Powersoft (Burlington, Mass.) has attracted integration
support from a number of CASE vendors.  The first shipping product (see
Figure 2, next page) is SE/Open for PowerBuilder from Houston-based LBMS
Inc. LBMS began shipping in late 1992.  It works with the LBMS Systems
Engineer upper CASE tool and the LBMS Information Manager, its
repository.

SE/Open imports two types of field definitions from PowerBuilder into
Systems Engineer: validation rules and display formats.  Systems Engineer
does not currently provide for field validation and display formats on
entity relationship models.  Both features support integrity by
controlling allowable field entries.  Because PowerBuilder handles
formats and validation differently based on the back-end database used
(SQL Server, Oracle, or SQLBase), this specification proves more physical
than logical.  The first version of SE/Open sends validation and format
rules back to PowerBuilder, but only if the table already exists in both
environments.  SE/Open does not yet create PowerBuilder tables.

LBMS is revising its products so that PowerBuilder can directly access
the Information Manager repository.  This will improve the level of
integration and eliminate some redundancy.  It also gives PowerBuilder
developers access to LBMS's version control, configuration management,
multiuser concurrency control, and repository-reporting features such as
impact analysis.  In addition, LBMS is working on GUI-design techniques
for Systems Engineer.  These features will enable developers to specify
what type of window or control (form, list box, etc.) implements a data
object.

Bachman Information Systems (Burlington, Mass.) has also announced an
agreement to integrate the Bachman tool set with PowerBuilder.  Bachman
is developing a module called Component Designer, for delivery in
mid-1993.  This will take logic from the Bachman/Analyst data-modeling
tool and transfer it to PowerBuilder.  Bachman was designing this product
at press time and could not reveal specific details regarding the
integration.

CASE provides only one component of a fully stocked developer's tool
chest.  Front-end application generators often fail to provide the
complete tool sets developers need.  Often, however, these are available
from third parties.  If alliances such as these extend to other utilities
such as testing aids, for example, the client/server market as a whole
would grow stronger.

The second approach to providing client/server I-CASE involves
application generators provided by CASE vendors.  Two vendors pursuing
this strategy are Intersolv (Rockville, Md.) and Intellicorp (Mountain
View, Calif.).

Intersolv now owns Excelerator, one of the earliest CASE tools to become
popular on DOS microcomputers, and recently released version 1.1 of
Excelerator II for Windows and OS/2.  (The original Excelerator is a DOS
graphics-mode package.) Intersolv also markets an application generator
called APS.

While both Intersolv products have their own repository, they now enjoy a
greater degree of repository data exchange.  Intersolv redesigned
Excelerator II's repository to make it more compatible with the APS
repository.  This LAN-based repository uses Sybase SQL Server as its
database engine.  Excelerator also performs schema generation and reverse
engineering for SQL Server, Oracle, and other client/server databases.

Excelerator II also works with APS's screen designer.  A user can design
screens in the CASE tool and pass them into APS via dictionary linkages.
APS adds other application painting features and generates both client
and server programs, as well as translates embedded SQL into stored
procedures.

Intersolv also enhanced Excelerator by adding event modeling and
state-transition diagrams because these are more useful to client/server
developers.  The company plans to add object-oriented modeling to future
releases.

Intellicorp's Pro-Kappa for UNIX and Kappa-PC for Windows are hybrid
development environments that combine object-oriented modeling, graphical
application development, expert-system features, and access to both
client/server databases and other CASE tools.

Pro-Kappa uses object-oriented models rather than entity relationship
diagrams.  It is able to map relational databases to its object models,
however.  A table maps to a class, a record maps to an object instance,
and a field maps to a slot in the class definition.  When Pro-Kappa
generates a front-end application, it converts this mapping to the
appropriate SQL calls.

The Kappa products blur the usual distinction between CASE tools and
application generators by acting as both.  The object-oriented model in
Kappa emphasizes events that trigger operations.  Its screen designer can
associate dialog windows with processes on an event diagram.  Kappa-PC
generates front-end applications from the model in the form of either C
or C++ source code, Windows executables, or DLLs.

Intellicorp's CASE Connection product imports entity-relationship diagram
specifications from Knowledgeware's ADW (Application Development
Workbench) encyclopedia and translates them into the object models used
by Pro-Kappa.

Another example of access to a CASE tool's data by an application
generator is a cooperative agreement between Logic Works and Four Seasons
Software (Edison, N.J.).  Four Seasons produces 4S-BriefCase, an
application generator.  Developers using ERwin/ERX to generate
DBMS-specific DDL scripts can import these script files into
4S-BriefCase's data dictionary.  4S-BriefCase then generates a default
menu structure, forms and reports for each table, and
referential-integrity checks.

The first level of integration between ERwin/ERX and 4S-BriefCase makes
ERwin/ERX a data-modeling front end that populates the 4S-BriefCase data
dictionary.  4S-BriefCase requires the SQL DDL script coded in the syntax
of a specific DBMS such as SQL Server or Oracle.  It does not accept ANSI
standard SQL.  Because many other CASE tools generate schema for the same
server databases, it should be possible to feed 4S-BriefCase from other
CASE tools.

Using DDL script files as an intermediary between a CASE tool and an
application generator is akin to using comma-separated files to exchange
data between DBMS products.  The integration is minimal and fleeting
because the redundancy means that a change in either product creates an
instant disparity.

Neither CASE tools nor front-end application generators have a definitive
standard for data-dictionary formats.  The lack of standards implies that
each CASE vendor must choose which front ends to support.  Front-end
vendors must chase CASE tool vendors or risk appearing like wallflowers
at a high-school party.  When CASE data-format standards gain more
momentum, they will prove helpful toward integration of CASE products.

The many-to-many relationship between CASE tools and front ends compares
to that between front ends and database back ends.  Over the last few
years, only a few back ends such as SQL Server and Oracle attracted
support by large numbers of front ends.  Now, however, a middleware
market is emerging to open up access to a much wider variety of back
ends, especially mainframe-base systems hosting legacy applications.
(See "Client/Server Middleware: Making Connections across the Enterprise"
by Richard Finkelstein, DBMS, January 1993.)

Front and back ends that talk to middleware layers automatically interact
with a growing list of other products (at least in theory).  If possible,
an analogous type of middleware must appear to resolve the problems
created by many-to-many relationships, not only between CASE tools and
front ends, but between all types of system-development tools.

Until tool-oriented middleware appears, vendors that do not form explicit
alliances can choose to open their architectures to attract integration.
Matesys (Larkspur, Calif.) is publicizing the repository format of
ObjectView, its front end.  Visible Systems (Waltham, Mass.) plans to
document the data dictionary of its Visible Analyst, a CASE tool that
does some nice SQL table generation.

LogicWorks, like Intellicorp, has also chosen SQL Server to store its
CASE dictionary, which permits developers to query the dictionary using
their favorite SQL Server front end.  ERwin/ERX currently lacks a data
dictionary (the diagram file stores all model details).  It may also
prompt front-end development products to use this data as input to
application generators.  Compared to exchanging DDL script files, this
technique eliminates redundancy.

On the other side, at least one front-end application generator
incorporates CASE-like features.  ObjectView 2.0 includes a simple
logical data-modeling feature.  It uses drag and drop to establish
relationships between tables.  ObjectView generates default form layouts
from the model.  This functionality does not match that of a full-fledged
database-design CASE tool.  It does, however, combine some of the
analytical rigor associated with data modeling and the fast and flexible
aspects of prototyping.

Summary

CASE vendors and tools integrate with client/server DBMSs on the back end
and application generators on the front end.  Several different
strategies link these two technologies.  More alliances and additional
techniques will likely emerge over the next few years.  This trend,
although still in its infancy, promises developers a broader and stronger
arsenal of tools with which they can build applications.

You classify CASE methods by the part of the system they model.  CASE
methods typically model either data, processes, or the interactions
between processes and data.

Process and Process-Control Modeling Methods

Decomposition Diagrams.

Decomposition diagrams are inverted tree structures that show how system
functions decompose into processing primitives.  At the root of the
diagram resides a single, general activity, usually displayed at the top
of the diagram.  The first level below the root shows a set of more
detailed activities that, taken together, are equivalent to the root
activity.  These activities are placed in the sequence they should be
performed.  A step that can't be started until after another step
completes will follow that step in the diagram.  Each of these detailed
steps are then decomposed in the same way until some primitive level of
functionality is reached.

Common notations include organization charts (the root is centered at the
top, processes are represented by boxes, and a single, branching line
connects the children to the parent at each level); Warnier-Orr diagrams
(the root is centered on the left, processes are represented by text
strings stacked one below another, and a single curly brace separates the
children from their parent); and indented lists (the root is in the upper
left corner, processes are represented by elongated rectangles, and all
children are listed beneath their parents).

Other, more complex diagrams of this form have data references that cause
them to be classified as interaction diagrams.  These include structure
charts (organizational charts with control information and data flows
shown along separated connecting lines), HIPO charts (organizational
charts with input and output data specifications for each process), and
HOS diagrams (HIPO charts with control structures defined at each branch
point).

State Transition Diagrams.

State transition diagrams are directed graphs (circles, boxes, or lines
connected by arrows).  They model processing behavior as a set of events
that move a system from one state to another.  Processing activity is
associated with the transition from state to state.  State transition
diagrams are typically used to model the behavior of individual system
components separately.  One or more high-level diagrams can be defined to
show the interactions of these components.

Simple diagrams ignore the processing aspects of the system and focus on
the states and the transitions.  Event responses are nearly always
represented as arrows.  In some diagrams the arrow is labeled with the
event and in other diagrams the arrow is labeled with the processing
response.  Diagrams of real-time, process-control systems are more
complex, adding new notations and labels to allow the specification of
both events and the timing and nature of associated processing.  Rigorous
object-oriented design diagrams are of this latter type.

Data- and Object-Modeling Methods

Entity Relationship Diagrams.

Entity relationship diagrams, known as ERDs, model the structure of data
as a network of interconnected units.  The facts that can be collected
about a system are referred to as attributes.  Through the process of
normalization, these attributes are grouped into units known as entities.
 Entities are normally displayed on a diagram with squares or rectangles.
 Entities and attributes represent the basic structure of the data.  The
lines that connect the entities together are called relationships.
Rather than being structural in nature, they represent rules that
restrict the ways in which data can be added to the structure.
Relationships establish the definition of data integrity.

Notations differ typically by the way in which relationship lines are
drawn.  Some notations allow multiple relationship lines to be joined
while others require an intermediate entity to be defined.  Some have a
notation for mutually exclusive relationships and others do not.  Some
notations use single- and double-arrow terminators, some use single lines
and crows feet (an inverted arrowhead), and some simply use single lines
with numeric labels.

Inheritance Diagrams.

Inheritance diagrams model object structure in a few different ways.  One
common diagram, known as a "class hierarchy," models object structure
with an inverted tree.  The nodes of the tree represent object classes.
The links between the nodes show specializations of the parent class.
The more general parent is always shown higher on the diagram than its
more specialized children.  At the root of the tree is the most
generalized class, the foundation class for the entire tree.  Each node
below the root specifies only the structural differences between itself
and its parent or parents.  The attributes of any class in the tree are
the attributes defined for the class itself plus every attribute defined
along a direct line between it and the root (along all paths if there are
more than one).  Inheritance diagrams also define the types of activities
that the classes can engage in.  A particular class will engage in the
activities defined for it along with all activities that have been
defined along all inheritance paths to the root.

A newer notation shows inheritance as a class network.  This diagram is
similar to an ERD with specialized associations for inheritance.  (Other
associations show implementation dependencies.) The root class is not
typically shown on this type of diagram to reduce the number of lines.

Process-Data Interaction Modeling Methods

Data Flow Diagrams.

Data flow diagrams are designed to model the movement of data through a
system showing all of its transformations.  Data moves along data flows
from sources (known as external entities) through processes that
transform the data, and into temporary storage locations known as data
stores.  Data flows out of these temporary stores, is transformed by
additional processes, and is delivered to external entities that serve as
the ultimate destinations for the data.  The entire system can be
represented in abstract form on a single diagram known as a context
diagram.  Process details are shown with separate data flow diagrams for
each process and the processes on those diagrams are detailed on other
diagrams.  Each subsequent level of this hierarchy describes the system
in greater detail.

The primary notational differences are in the symbol sets.  In all cases,
data flows are drawn as arrows.  Your-don-DeMarco diagrams use squares
for external entities, circles for processes, and parallel lines for data
stores. Gane and Sarson diagrams use double squares for external
entities, rounded rectangles for processes, and open-ended rectangles for
data stores.  Extensions to these notations have been added for modeling
real-time controls and for object-oriented design.

Matrices.

Matrices represent the interaction of processes and data as cell values
in a spreadsheet.  The data is named along one axis and the processes
named along another.  A blank cell value indicates that the corresponding
data item and process do not interact.  Different types of interaction
can be defined by using a variety of cell values.  (X simply identifies
an interaction; C = Create, R = Read, U = Update, and D = Delete specify
the type of interaction, and so on) Although their expressive power is
limited, matrices can be used for a wide variety of purposes by changing
the items named on the axes.

Action Diagrams.

Action diagrams model process details as nested blocks of logic.  They
are considered interaction diagrams because they show data and process
details in the same diagram.  Individual logical statements represent the
standard actions that a process can perform (such as read, write,
assign).  These statements are organized by control structures
(if-then-else, do while, and so forth) into blocks, indicated by an
enclosing bracket placed on the left.  These blocks are nested within
other control blocks and they are all nested within a single outer block
representing the process itself.  Some implementations are detailed
enough to allow this logic to be automatically converted into source
code.

References

"A Guide to Information Engineering Using the IEF." Plano, Texas: Texas
Instruments, 1988.

Martin, James and Carma McClure.  Structured Techniques for Computing.
Englewood Cliffs, New Jersey: Prentice-Hall, 1985.
-------------------------------------------------------------------------
Type:      cover story
Topic:     Computer-Aided Software Engineering
           Client/Server Architecture
           Data Base Design
           Applications Programming
           Program Development Software
           Program Development Techniques
           New Technique
           Integrated Systems
           Industry Analysis
           Trends
           Computer Software Industry
           Data Base Front-End Software


Record#:   13 427 252.
                              *** End ***
