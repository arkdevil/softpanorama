*****  Computer Select, January 1994  : Articles *****

Journal:    Distributed Computing Monitor  Jan 1993 v8 n1 p3(17)
COPYRIGHT Patricia Seybold Group 1993
-------------------------------------------------------------------------
Title:     Component software: a market perspective on the coming
           revolution in solutions development.
Author:    Lavoie, D.
           Baetjer, H.
           Tulloh, W.
           Langlois, R.


-------------------------------------------------------------------------
Full Text:

The Drive toward a Software Components Marketplace

The Software Industry is Being Revolutionized

Something big is happening to the software industry. Its property rights
systems, management philosophies, pricing and marketing strategies,
accounting methods, and distribution channels are all undergoing a
revolutionary transformation. The software industry is changing rapidly
and in many ways unpredictably, but the change is not random. We see a
definite pattern behind the current changes in the industry, and the
pattern suggests that a whole new world, a components marketplace, is
beginning to emerge.

A combination of economic competition and continuing advances in computer
hardware are driving the industry to modularize its systems into
reusable, and eventually marketable, components. The logic at work in the
evolution of software practices, languages, and systems is a logic of
improving our capacity to cope with complexity and respondto
unpredictable change.

While there is a compelling logic to the changes going on in the
industry, components markets are not inevitable. Many
obstacles--technological, legal, cultural, andeconomic--stand in the way
of flourishing component markets. In this report, we intend to address
the hard problems that need to be solved before software components can
become a commercial reality.

OOPS Is the Latest Step in an Evolutionary Process

The dynamic driving the transformation of programming practices has led
to the gradual improvement of our capacity to discover new knowledge, to
store it in reusable form, and to modify it without incurring costly
secondary effects. The same dynamic that made the breaking of programs
into subroutines an improvement over the spaghetti code of earlier years
and structured programming an improvement over the undisciplined use of
subroutines is now driving the industry to object-oriented programming
systems (OOPS).

The rage in the industry today over object orientation is an instance of
the excessive hype that plagues this industry, but OOPS is no passing
fad. A recent spending survey conducted by the International Data
Corporation (Framingham, Massachusetts) reported that "almost half of
1,600 respondents are becoming involved with object-oriented technology
despite the cost of implementing it."

OOPS IS A RADICAL APPROACH TO CREATING SOFTWARE. Object orientation can
be seen as both an old and a new idea. It represents the accumulation of
the experience of several decades of programmers trying to create new
programs and modify old ones, that is, to make and cope with change. And
yet, in many ways, it represents a radically new approach to software
which can significantly improve its evolvability. Making more evolvable
software will, in turn, increase the long-term value of software capital
investments.

Modularity: An Economic Principle for Reducing Complexity

This dynamic works for general reasons based on economic principles. The
study of market processes sheds light on how coordinating processes
facilitate economic development. Just as effective modularity helps
programmers handle the complexity of software, so effective property
rights institutions help entrepreneurs handle the complexity of
production problems. Economic development can be understood as an
improvement in "social intelligence," the ability of coordinating
institutions to help decision-makers adapt to their evolving
environments. Wealth creation is driven by improvements in the effective
management of complex production processes.

Object orientation enhances productivity in software because it helps us
to carve complex problems into smaller, more modular pieces. This
"division of knowledge" contributes directly to our ability to manage
complexity by extending the economic structureof production.

Component Markets Are the Future OOPS Points Toward

Object orientation widens the focus of programming from individual
projects toevolving systems of reusable components within the firm. The
increased evolvability of an object-oriented world is driving the dynamic
to its next stage: the emergence of component markets among firms.
Markets can be thought of as logical extensions of the move to object
orientation, further widening the focus of programming from the firm to
the whole industry, and increasing the evolvability of software systems.

Software production has been taking place in relatively isolated
individual projects; a greater synergy among producers seems possible.
Improvements in modularity enable two kinds of advances in our ability to
manage complexity: they facilitate internal economies of scope, and they
set the stage for the growth of a full-scale component marketplace.
Component markets open up new opportunities for improving our productive
synergies. This idea presents new difficulties for some, as well as new
profit opportunities for those who know how to interpret market signals.
We see the potential for a radical increase in software productivity. But
there are some sobering challenges that need to be met before the
productivity gains of a fully integrated components market can be reaped.
Among the challenges are the lack of uniform standards, the difficulties
of distribution, and the uncertainties of intellectual property rights.

Market-Process Economics and Object-Oriented Programming

Perspectives on Change from Economics and Software Engineering

This report employs ideas from two quite separate areas of scholarship,
located within economics and software engineering, which address coping
with a complex world permeated with human error. We live in a world of
complexity and unexpected change, which makes error inevitable. The
future is so unpredictable that about the only thing we can be sure of is
that mistakes will occur.

From economics, the market-process school has addressed the importance of
learning and adaptability when faced with rapid change, and it has
contributed a useful conceptual framework for dealing with maintaining
the value of capital in the face of errorand subsequent learning.

Market-Process Economics Stresses Role of Knowledge

Market-process economics distinguishes itself from other approaches by
the centrality it places on certain issues surrounding the use of
knowledge in complex social coordinative processes. This view of
knowledge arose primarily from considerations about the failure of
centralized economic planning and has led to a powerful case for
voluntary and decentralized solutions to economic policy problems.

From software engineering, the object-oriented programming movement also
confronts head-on the pervasiveness of change, and it has also
contributed a useful conceptual framework for dealing with the issue of
coping with complexity. The real advantages of object orientation arise
from the greater maintainability, or, one might say, ability to evolve,
of software that is engineered according to its principles. OOPS, in this
sense, is well-named, for it is an approach to programming for a world of
error.

OOPS Is a "Learning" Approach to Software Development

Much of mainstream computer science has assumed that users of software
know exactly what they want. It puts its emphasis on creating logically
correct programs andon meeting the specifications, which are assumed to
have been already worked out, somehow. Object orientation does not go
into programming assuming that we know what we want the software to do.
It focuses more on the processes of finding out what the specifications
ought to be and modifying the software when we change our minds.

CONVERGING IDEA ACROSS ECONOMICS AND SOFTWARE ENGINEERING. Market-process
economics resists a similar tendency among many economists to assume away
the problem of error. In the literature surrounding object-oriented
principles of software design can be found a kind of analysis that is
familiar to market-process economists. It emphasizes the same issues of
why an effective division of knowledge is necessary to the solution of
complex problems. Software designers are seeing in microcosm the same
kinds of problems that market-process economics takes to be decisive for
economic performance.

Components Markets Are a Mechanism to Deal with Complexity

The software industry has been gradually developing appropriate
techniques and modes of organization for managing complexity, and the
next step in this direction is markets. The evolution of the industry
exhibits an order, a logic driven by the competitive selection of
practices that permit increasing complexity. As component markets begin
to evolve, we believe that the software industry's ability to manage
complexity will significantly improve, and that this will lead to higher
productivity, expanded markets, new functionality for customers, and
faster delivery of software products.

The solution to the challenge posed by complexity has to do with what
market-process economists call the division of knowledge and with what
proponents of object orientation call modularity. Coordination processes
that facilitate coping with complexity involve finding ways of dividing
complex tasks into manageable pieces and then setting up systems for
mutual adjustment of the pieces. The knowledge that drives coordination
needs to be divided among the participants, not concentrated in the
control of a command hierarchy. Managers need to abandon centralized
approaches to production, whether we are talking about programs or other
products. They need to rely on a decentralized process of coordination in
which a system of rules is developed, by orientation to which the
separate decisions of independent agents can be brought into mutual
adjustment.

We conceive of markets as fundamentally knowledge-conveying processes,
analogous in many ways to languages. We believe that the study of any
market in the contemporary world is a study of the management of
complexity. Complex systems can be more effectively managed to promote
the effective invention, creation, discovery, interpretation,
communication, and use of knowledge. Under the appropriate institutional
conditions, markets can be very effective aids to the management of
complexity.

Software: A Special Industry

A Prototypical "Pure Knowledge" Industry

Because its product is, in a sense, pure knowledge, focusing on the
software industry helps to bring out the knowledge aspects of economic
processes, which are important inany industry. It's possible to miss the
knowledge aspects of the steel plate industry and remain preoccupied with
physical aspects of steel. Yet, in fact, steel plate contains not only
the molecules that make up its physical existence, but also vast amounts
of knowledge accrued from decades of metallurgical practices. In the case
of software, the physicality is not there, and so it can't get in the
way. Here we see with great clarity the knowledge problems in their pure
form, unsullied by extraneous considerations. The knowledge problemswe
see in software involve the effective management of ever-increasing
complexity.

Take the more general economic problem of the maintenance of capital. The
pure-knowledge form of software capital has some interesting properties:
it never wears out from repeated use, and it is easy to reproduce, thus
making ownership rights difficult to protect. The maintenance of software
"capital equipment" is a matter of the ease with which programs can be
found, understood, and updated, and it has nothing whatsoever to do with
anything wearing out.

SOFTWARE INDUSTRY'S EXPERIENCE ANTICIPATES FUTURE OF ENTIRE ECONOMY.
Production processes in the economy as a whole--which economic
rhetoricians still talk about as if they always involve material
transformations of raw materials into physical consumer goods--are really
matters of the maintenance and enhancement of value. Today, they more and
more take the form of information services, helping us to get a better
handle on the information to which we already have physical access.
Modern production is no longer exemplified by the transformation of iron
ore into steel, but by the transformation of an unsorted collection of
data into a sorted list. Software is an important industry to study
because it has had to face a number of special challenges that knowledge
presents to economic production at large.

The Complexity Dynamic and the Software Industry

Perhaps the most important implication of software's being a knowledge
product is the extent to which software engineering has faced the
problems of complexity management which all industries face to some
degree today. Throughout modern industry, what we will be calling the
complexity dynamic has been operating. (See Illustration 1.) It has been
moving back the resource constraints and thus exposing the limits of our
abilityto manage complexity.

SOFTWARE INDUSTRY FACES MORE INTENSE VERSION OF THE DYNAMIC. What makes
the software industry instructive is that it faces a more intense version
of the dynamic. It is driven by a particularly competitive environment,
so that, in some ways, it has had to learn more (and learn it faster)
about coping with complexity than others have had to. As the rest of
modern industry evolves more of its capital into the knowledge-capital
form, it will benefit from the lessons software has to teach about
complexity management.

Many commentators on the software industry talk of a software crisis.
While hardware keeps delivering more for less, it is said, software
struggles to keep up. This may be a misguided comparison from the outset.
First of all, the phenomenal productivity and quality gains that have
been enjoyed in computer hardware make this an unusually high standard
against which to judge an industry. Secondly, there is no reason to
expect the hardware and software industries to work similarly. Software
is, of course, influenced strongly by what happens in hardware, but it
tackles utterly different technological problems. Doubling productivity
of code is not the same kind of problem as doubling the density of
semiconductors.

Complexity: The Barrier to Engineering after Resource Constraints Are
Gone

Engineering is about pushing back constraints, making things do what we
want. Historically, engineering ambitions have been constrained primarily
by the limits of physical laws. Civil or electrical engineering has
naturally focused on resource constraints, the limitations of materials,
the way electricity works, the laws of magnetic forces, etc. But human
ambitions increasingly push us to construct systems limited not so much
by physical circumstances as by our own ability to keep track of them.

As our advances in the physical sciences enable us to push resource
constraints further and further out, we find that our actions are bumping
into a different kind of constraint, complexity constraints. The hardware
would let us do more, but we cannot get our hands around that much
complexity. We cannot let the systems we build exceed our capacity to
develop, understand, and modify them. When the complexity becomes too
great, we risk overall system failure, because we find we need all our
energies just to figure out what is going on and have none left to
improve the system.

PERFORMANCE: A MEASURE OF KNOWLEDGE TRANSFER AND EFFICIENCY. Performance
concerns, the effectiveness of the software's use of computational
resources, never retreat from the scene. They just shift to bigger and
faster metrics. It is not that performance doesn't matter; it's that what
matters is not only the performance of the computer running the code, but
also that of the other programmers reading or modifying it. Industry
people routinely distinguish between programmers and users, but they are
coming to realize that some of the most important "users" of code are the
reusers, the programmers. The code needs to "work" well not only as
equipment for the users but also as working capital for the reusers, the
producers of future software.

Each time we push the resource constraints back, we face still more
complexity in programmers' ambitions, in customers' demands, in the
challenges of distributed computing. As soon as we find ways to manage
greater complexity, we rediscover resource constraints blocking our
heightened ambitions. Whichever is binding at the moment, the challenge
of pushing back both kinds of constraints makes software engineering
especially difficult. No matter how fast the hardware works, or how big
the storage devices get, the software engineers can quickly use up the
slack.

New Approaches Required to Break through Complexity Constraints

We have learned a great deal over the years about pushing back resource
constraints, but the challenges posed by complexity seem more difficult
to get a handle on. Software engineering is not unique in finding itself
challenged by complexity constraints, but, in many ways, it may be the
best case to illustrate the nature of the challenge.

Judged by standards more appropriate to its own circumstances--trying to
push back both resource and complexity constraints--the software industry
has done quite well. But the current software industry may be reaching
the limits of its ability to handle complexity with the traditional
technologies and management practices it deploys. There may now be a need
for a radical transformation of technologies and practices in order to
continue pushing the complexity constraints further back.

The Software Industry's Evolutionary Path

Hardware Evolution: Primary Influence on Software Development

What drives the software industry more than any other single factor is
the continuing fall in hardware costs. In 1975, one of the pioneers of
computer technology, Gordon Bell, observed that core memory prices and
overall system prices were falling at a rate of 20 per cent per year. The
introduction of semiconductor memories by Intel led to a regular 36 per
cent decline in price per bit every year, or a factor of 10 every five
years. The steady drop in prices of memory space and the increasing
speeds of hardware have continually opened up opportunities for software
to grow in complexity.

REMOVAL OF MEMORY CONSTRAINT EXPOSES NEW COMPLEXITY ISSUES. The effects
on programming are that software is increasingly constrained not by
hardware limits but by the level of complexity that can be effectively
managed by programmers. Programmers usually have to work in teams, and
they must make their work understandable to one another. The skill of
creating clever code that economizes on microseconds or bytes of space,
that is, which husbands hardware resources but is difficult to understand
or modify, becomes less useful. The skill of making software continually
more complex while continuing to reach high performance standards at
whatever scale the hardware now makes possible becomes more useful.

Three Stages in the Battle to Master Software Complexity

The computer industry can be described as having gone through two major
stages and now entering a third in its continuing battle with complexity.
The shifts are symbolized by, and connected to, the changes in hardware
platforms that have taken place, from a world of only a few large
machines to a world populated by unconnected personal machines, a
condition that characterizes the third stage, which we believe will
involve component markets.

STAGE #1: THE HOST-CENTRIC ERA. In the early years, the hardware
platforms were large mainframes. Given the expense of running these
systems, the applications consisted primarily of a small number of
high-value, high-volume business applications: accounting, payroll,
inventory. The mainframes tended to run large, complex software packages
which were typically difficult to improve and maintain, that is, which
were not very evolvable. The computer was still thought of as a large and
fast calculator, and access to it was limited to a narrow group of
experts.

In 1965, the first successful minicomputer was introduced, expanding the
market for computer users. This change did not, however, change the
fundamental industry structure. Applications remained complex, and
custom-designed solutions were available only to a few users and had only
a few high-value uses.

PCs Changed Everything in Software and Markets

STAGE #2: ENTER THE PERSONAL COMPUTER. The second stage, the Age of the
PC, started in 1975 with the now historic issue of Popular Electronics
introducing the Altair. Suddenly, power was radically decentralized,
shifted into the hands of individuals, brought to a human scale. Personal
computers greatly expanded computer literacy beyond the narrow group of
experts who controlled the mainframes and effectively invaded the modern
offices in domains that mainframes and minicomputers had never touched.
It has also shifted new complexity challenges from customers to
developers, who are trying to build software applications for graphical
user interfaces.

Pricing of software products in the PC Age is charge-per-copy for
copyright-protected copies of large application packages. Distribution
channels are retail, throughbig, high-volume chain stores or mail order
for off-the-shelf products and through consultants, specialized
integrators, VARs, and management information systems departments for
custom products.

Age of the Network: The Next Step in the Industry's Evolution

STAGE #3: INTERPERSONAL COMPUTING. The third stage is the Age of the
Network. If the age of big iron was impersonal and the PC Age was
personal, the next age is interpersonal. The early signs of this stage
might be the development of Ethernet at Xerox PARC andwork on distributed
computing at Datapoint Corporaion (San Antonio, Texas). Although local
area networks are becoming widespread and are changing the way many
people think about computers, the network stage is still very much in
embryo, and its radical transformations are only just beginning.

The decentralization wrought by the PC is irreversible, but decentralized
decision-makers are coming back into contact with one another through
networks. The forces of this stage are reintegrating users who were
driven apart in the PC Age, but they are not returning to the centralized
systems of the past. The logic of the third stage is one of cultivating
an environment where the once-isolated PCs are increasingly beginning to
communicate and interact with one another.

Networks Shift Focus of Software Creators to Managing Complexity

Through the first and second stages, people have tended to think
primarily in terms of pushing back resource constraints. With the move to
distributed computing, the main issue will be pushing back the complexity
constraints.

The fundamental philosophy of software has undergone a sea change through
the decentralizing dynamic of the PC revolution, taking the industry far
away from its early preoccupation with number-crunching and toward the
more humanities-oriented viewof software we have today. The "computer,"
once an overgrown calculator, became a handy tool for all sorts of
personal and business purposes. Computers not only perform computation,
in the sense of solving equations quickly and accurately, but they also
enable sophisticated user interfaces, graphics, word processing, and
outlining, which can help us enormously in our use of words and graphics.
The idea of cruching numbers itself widens, becoming more a matter of
user-friendly tools for the visualization and interpretation of
quantitive relationships. Somehow, in the transformation, computer
science became less a branch of mathematics and more an autonomous field,
with links to the visual arts, communications, philosophy, and psychology
as strong as those to mathematics andphysics.

So then, what is the software philosophy for the Age of Networks? Object
orientation, we believe, but not only as it is now understood here at the
end of the PC Age, that is, as good programming practices that many
isolated programmers would be wise to adopt individually. Understood as a
philosophy for the cooperative handling of complexity, object orientation
represents the beginning of a profound revolution in the software
industry. In combination with an infrastructure of networks, this spells
the basis of a wholenew world, as different from today's atomized
software world as that world is from its predecessor.

Since we are only about to begin the third stage, we can only glimpse the
profound changes on the horizon. One thing, we think, is clear:
Programming languages, analysismethods, and practices in general are
going to need to manage greater and greater degreesof complexity.

The Power of Object-Oriented Software

Why Is OOPS Important to Component Software?

Among the hottest ideas in software technology today is object-oriented
programming systems (OOPS). What is this OOPS phenomenon, anyhow? And why
is it important for the emergence of markets in software components?

From our point of view, the movement is significant because it addresses
the twin challenges posed by the complexity dynamic. It is improving our
ability to produce software as evolvable systems of well-carved-out
modules.

MODULARITY: THE BIG PAYOFF FROM OBJECT ORIENTATION. The advantages of
object orientation stem from the fact that this approach to programming
improves modularity, which improves software's ability to be evolved in a
world of increasing complexity. It is this improved modularity and
evolvability that will, in turn, pave the way for component markets.
Perhaps the single most important factor pushing back the complexity
constraint is the quality of modularity decisions. The key importance of
object orientation, in our view, is that it permits programming to take
advantage of the complexity dynamic and reach higher levels of
complexity.

Economic growth through increased productivity requires the storage of
knowledge in a form suitable for reuse. When the knowledge is
sufficiently complex, putting itinto reusable form may be as difficult as
coming up with it in the first place. When the overall complexity is too
great for us to grasp, two related challenges present themselves to us:
abstraction and coordination.

ABSTRACTION. Abstraction is the challenge of how to break the problem up
intosmaller, more do-able pieces. Improvements in abstraction are paving
the way for a profound transformation of the software production process.
The process is changing from one that focuses on individual projects into
one that develops systems of reusable components applicable to many
projects.

COORDINATION. Coordination is the challenge of how, in a sense, to put
the pieces back together. The transformation of the production process
will, in turn, make possible better solutions to the coordination
challenge by opening up extensive components markets for the distribution
of software.

What Is Object Orientation?

What are the significant features of object orientation that allow it to
play this role in components markets? There are different interpretations
of the philosophy which stress different features as crucial. In our
view, the interpretations which make the most sense stress the following
features:

* Abstraction, or identifying "the essential characteristics of an object
that distinguish it from all other kinds of objects and thus provide
crisply defined conceptual boundaries, relative to the perspective of the
viewer" (Grady Booch, Object-Oriented Design with Applications (Benjamin
Cummings, Redwood City, Calif., 1990), p.39.)

* Inheritance, through a hierarchical class structure

* Encapsulation, or the packaging of data together with its corresponding
procedures

* Information-hiding, or making the internal details of a module
inaccessible to other modules

* Polymorphism, or the hbiding of alternative procedures behind a common
interface

How Objects Help Developers Conquer Complexity

Object orientation addresses the challenge of increasing complexity
primarily by the use of abstraction, inheritance, and the inherent
modularity of object-oriented software.

ABSTRACTION. Software engineers call the basic issue of how to carve up
complex problems the issue of abstraction. Complex problems need to get
broken up into smaller, more humanly manageable pieces. Abstraction
carves out some aspect of the problem that can be solved in advance, in
general, for a large number of identifiably similar cases. A good
abstraction, as one software engineer put it, is one that "emphasizes
details that are significant to the reader or user and suppresses details
that are, at least for the moment, immaterial or diversionary."

INHERITANCE. Finding already written functionality by browsing a class
hierarchy and writing new code quickly by subclassing are among the most
rewarding experiences of object-oriented programming. One can look at
inheritance relations as a kind ofcontract whereby the superclass
provides contract boilerplate which the subclass use to tailor the
particular contractual terms for certain cases. To maintain the logical
integrity--and thus understandability--of this structure, it is important
to be sure subclasses are genuinely special cases of the more general
superclass under which they are placed.

MODULARITY. The common strength of polymorphism, information-hiding, and
encapsulation is that they improve modularity boundaries by removing
unnecessary dependencies among modules. Proper modularity permits a
decentralization of decision-making, with coordination among the
decisions being secured by message-passing among modules. This helps
software engineers minimize what economists call negative externalities.
More effective modularity boundaries open up elbowroom for
decision-makers, allowing them to use initiative within a certain
well-defined domain, with a reduced danger of setting in motion streams
of unintended negative consequences in other domains. Relatively narrow
and explicit interfaces make coordination among encapsulated modules
easier.

The Benefits of OOPS Are Not Free and Easy, but They Are Available

Object-oriented technologies are not going to make software an easy
business. Claims that OOPS can exponentially increase productivity exceed
credibility. Many of the claims for radical improvements over time are
verifiable, but the high up-front costs cannot be neglected.

But there's more to objects than hyperbole. After all, even such
excessively over-hyped movements in programming as artificial
intelligence (AI) or computer-assisted software engineering (CASE) tools
are more than mere hype. Each has made some real contributions, after the
dust settled around the initial exaggerated promises.

Object orientation promises to transform software production in a more
fundamental manner than AI and CASE tools ever did. Object orientation is
not so much a tool to be put to work within traditional software
production processes as it is a rethinking of the very nature of such
processes. It cannot substitute for human ingenuity, make programming
easy enough for toddlers, or automatically solve our problems for us. It
can make it much handier for us to solve our own problems, however, and
that can be extremely significant.

Object Orientation Software Life Cycle Is Rooted in Reality

Programmers who first encounter object orientation often react by
thinking that it only articulates what have always been their implicit
ideals of good programming practices, but puts it all so clearly that
living by those ideals is easier.

NEGLECTED ASPECTS OF SOFTWARE QUALITY. As Bertrand Meyer, president of
Interactive Software Engineering Incorporated (Goleta, California) and
designer of the Eiffel object-oriented programming environment, puts it,
traditional computer science training emphasizes two aspects of software
quality--correctness and robustness--and ignores extendibility,
reusability, and compatibility. The neglected aspects pertain to
software's existence in a world of time.

The student in a computer science class is typically asked to write a
program that does what the specifications demand. The specs are (somehow)
already there, and the programmer gives no thought to how to develop
them. Once the program is found to be correct, in that it does exactly
what the specs ask, and is robust, in that it works for a full range of
input parameters, the assignment is finished. The student is not asked to
come back to his program a year later and modify it.

BEFORE THE SPECS: PROTOTYPING AND DISCOVERY. In a world of continuous
change, software engineers need to open their temporal horizons beyond
the project. They need to attend to the before- and after-life of
software.

Software specifications are supposed to identify exactly the
functionality the customer wants. We know that customers cannot possibly
know exactly what is do-able, so that they can't write the specs by
themselves. Programmers, who tend to have a better idea about what is
do-able, cannot possibly know in advance what the customer wants. The
specifications should be written out of a dialogue between those who can
say what is doable and those who can say what is desirable. This is the
role of rapid prototyping.

AFTER THE SPECS: FLEXIBILITY AND MAINTENANCE. After the specifications
have been met, there is the problem of implementing changes, a major part
of the costs of software. Finding the documentation, figuring out where
the change is needed, fixing the new bugs the change over here causes
over there, fixing the bugs caused by fixing those bugs, and so on. These
are the changes that make object-oriented systems look good and
traditional approaches look bad. Systems that require less updating may
find object orientation less exciting, but users who have carried the
burden of frequent modification of old code will benefit enormously from
it.

Complexity Management and the Use of Knowledge

Understanding the principles of modularity can lead to a better use of
knowledge in the programming community, allowing our intellectual
creativity to complement that of others rather than conflict with or
duplicate it. A better use of our distributed knowledge could, in turn,
lead to very significant productivity gains over time, especially for
firms that confront significant complexity constraints.

The complexity dynamic rewards software executives who are able to
address the three elements of complexity management, making code that can
be more easily reused, evolved, and understood. The key to this will be
the shift in focus from viewing software production as a series of
separate, individual projects to viewing it as a system of components out
of which projects are made.

A Software Components Marketplace

What Kinds of Things Will Be Sold in the Components Market?

What does it mean to say "an active software components market?" First of
all, by components, we do not only mean Lego-style modules. We expect the
market in components to include a range of things that can be made
reusable, from utterly prefabricated, pluggable parts to individual
expertise made available through consulting contracts.

We anticipate a whole new set of institutions and practices surrounding
the production, marketing, pricing, and distribution of software. We
expect a profound transformation of the industry from its present
craft-production form into a sophisticated market system. This change
will permit humankind to significantly increase its intellectual
productivity, taking greater advantage of the division of labor and more
effectively saving up its intellectual achievements. It will, in a sense,
be a software industrial revolution.

In some ways, the imagery of the industrial revolution is helpful.  We
expect a shift to more emphasis on assembling code rather than on
building it from scratch.  In many ways, traditional approaches to
programming teach one to start with a blank sheet of paper and create a
whole program, whereas, in a components world, one needs to find already
written modules of functionality and piece them together into a whole
program. However, a better metaphor for the software components
revolution than Henry Ford's assembly lines for mass production would be
the Japanese auto industry's system of lean production. Here the aim in
organizing the production process is not to centrally control workers,
but to tap their decentralized knowledge and cultivate their use of
initiative. Lean production amounts to retaining the economies of scale
that accompanied the rise of mass production without the need to force
producers into mindless, repetitive tasks, or to force consumers to
compromise their differentiated tastes into an "average" taste.

The Changing Role of Programmers in the Components Market

The programmer as assembly line worker is neither a very appealing image
nor a very likely possibility. Mechanization in manufacturing tends, as
Leijonhufvud argues, to "replace workers with machines at precisely the
most repetitive, mechanical tasks, while at the same time creating a
range of new jobs that require the exercise of skill and judgment in the
operation, maintenance, repair, and refitting of the machinery." (Axel
Leijonhufvud, "Information Costs and the Division of Labour,"
International Social Science Journal, May 1989.)

The same tendency would apply in the case of software. The software
components world will involve enhancing a different set of skills than
have been cultivated in the craft age, but it will not turn software
production into a deskilled factory system. What matters for software is
not economies of scale in manufacturing, but achieving economies of scope
in product design. Indeed, one of the comments one hears most from
enthusiasts of object orientation is how much fun it makes programming,
how many dimensions of creativity it opens up and makes enjoyable. It
doesn't remove creativity; it redirects it toward problems that have not
yet been solved.

The Effect of Components Markets on Software Development

There are two general aspects of the complexity challenge: in one, focus
is inward into the firm, in the other, focus is outward into the larger
market context within which firms operate.

The inward aspect is about the role of management in the production
process and examines issues of how to manage an organization to make it
better able to cope with increasing complexity. Firms that find ways of
taking advantage of economies of scope or that find effective ways to
build modular systems can get an edge in the struggle to cope with
complexity.

The outward aspect is about the changing market context within which the
management of software production is taking place. Object technologies
are already enabling more reuse to take place within firms, but they have
not yet done much to improve the extent to which reuse can take place
between firms. The production process inside a software firm often seems
to be more isolated from that of others than it needs to be. Object
orientation moves us from seeing software production as a string of
isolated projects toward seeing the firm's total production process as an
integrated whole. But that whole is still thought of as what goes on
inside the company. The firm is still trying to direct large-scale
production across many stages inside one overall production plan. There
is not yet the refined degree of vertical and horizontal specialization
among firms which one sees in many well-developed markets.

The Role of OOPS in Components Markets

Object orientation helps get software into reusable component form, but
it doesn't, in itself, give producers the motivation or much effective
opportunity to actually do some reusing. Legal, economic, and cultural
changes are also needed to enable a vibrant market in components. The
fundamental changes of thinking in object orientation point beyond
themselves to a more interconnected production process, in which we
embody more knowledge into socially available form. These changes may be
laying the groundwork for a more thoroughgoing transformation of software
production than we have seen yet, the emergence of a vibrant market in
relatively small, reusable software components.

A COMPONENTS MARKET SCENARIO. Picture, then, a possible scenario for an
integrated, object-oriented software marketplace. Useful objects are
drawn not only from the user's own company library, but also from a vast
electronic marketplace via modem. And the searching is no longer
unidirectional. Specialist intermediaries help customers and producers
find one another. Some segments of the components market offer
off-the-shelf, reliable, prefabricated modules, which need only to be
assembled to be reused in numerous different applications. Other segments
involve "putting humans on the interface." Consulting activities spring
up to adapt components to the specific needs of the user. Arbitragers
emerge to help even out the price structure, driving underpriced
components up and overpriced components down.

In the information market, the buyers grope to locate the kinds of
functionality they want, and the sellers, to find customers for their
functionality. In short, we have the emergence of an organized,
interpersonal network for the exchange of software components. And we
think the gains from that exchange network are apt to create a great deal
of new wealth.

The Migration to Components Markets

To Obtain the Benefits of Markets, We Must Reorganize Production

In order to prosper in the coming software components revolution, firms
that develop software will be challenged to maintain coordination in the
development process. As specialization and division of knowledge
increase, today's complex production process will increasingly give way
to a complex structure of production spanning many organizations. As Fred
Brooks made clear in The Mythical Man Month (Addison-Wesley, 1974), the
current coordination challenges of software production are already
tremendous. Component software makes these challenges greater still by
involving more people whose efforts must be coordinated despite increased
separation across time and space. To meet this challenge, firms will have
to change the way they do business, and the changes will have to be
comprehensive.

Assuming that the days of building software applications from scratch are
numbered, how will managers coordinate increasingly dispersed
contributors to the production process? How will they align incentives so
that these dispersed contributors work together? How will they locate the
components produced? How will they assure component trustworthiness?
Meeting these challenges will require fundamental organizational change.
Success will therefore depend on management's willingness to make the
necessary changes and see them through.

The Concept of Capabilities in Firms and Markets

There are a range of possible organizational forms within corporations
with which these challenges might be met, each having strengths and
weaknesses. The key concept for managers to understand about these
organizational forms is the concept of capabilities in firms and markets.
The "capabilities school" of economics explicitly recognizes the division
of knowledge in the economy. It points out that firms have a pool of
tangible and intangible resources to draw on, and that patterns of these
capabilities significantly influence industry structure.

TYPES OF CAPABILITIES. Some of the kinds of capabilities are as follows:

* Internal capabilities, which are the firm's capital goods: equipment,
tools, stocks of goods, human skills and talent

* External capabilities, which are the resources available to a firm on
the market, either by simple purchase or by various contractual
arrangements

* Organizational capabilities, which are managment's abilities to marshal
effectively the firm's internal capabilities--its capital goods and human
capital

* Organizational learning, which is the valuable ability to develop new
capabilities rapidly and effectively

Which Capabilities Do You Need in the Components Era?

What are the organizational capabilities that firms will need to capture
the benefits of software components? Because most firms are just
beginning to develop these capabilities, a lot of organizational learning
still must occur. Managers will face a host of choices.

There will be questions of firm and product positioning in the evolving
division of knowledge: What are your current capabilities, and what
capabilities do you need to develop? Can you get them externally, or must
you develop them internally? What are the capabilities of your suppliers
and competitors? The answers to these questions will help reveal what
place the firm might take in the industry.

There will be major questions of how to structure the firm so it can take
its place: How can you set yourself up to take best advantage of your
current capabilities? What resources do you need? What systems must be in
place to develop the new capabilities you would like to have? Answers to
these questions will help guide specific organizational decisions.

Organizational Alternatives

The organizational changes that companies must make to reap the rewards
of component software are substantial, extending to virtually all aspects
of the software development organization. To make them will require
long-term management commitment. Of all the lessons we have learned in a
year's research of this topic, none has come through with the force and
unanimity of this one. Management must commit.

To reap the benefits of reuse, management must institute enterprise-wide,
i.e., cross-project organizational guidelines. Single-project
improvements--better project management--will be ineffectual. Top-level,
strategic support for reuse, aimed at achieving economies of scope, is
necessary. This support must be more than lip service. It means rolling
up shirtsleeves and changing the way the organization does business. Some
or all of the following may be involved:

* Changing the structure of project development teams

* Changing the way programmers are compensated

* Installing new procedures for gathering and distributing the reusable
components

* Changing accounting practices

* Initiating new kinds of contractual arrangements

These changes will be expensive, and they may be disturbing, but again,
they are an investment in the ability to produce software better, faster,
and cheaper in the future. If carried out effectively, they will yield
significant economies of scope. These economies do not come cheap, but
they pay off well.

Possibe Structures for Software Development Teams

How should programming teams be organized to obtain the benefits of
component software? Adele Goldberg, chairperson of ParcPlace Systems,
Inc. (Cupertino, California), has discussed three different approaches.
We draw on her work here.

DISTRIBUTED RESPONSIBILITY. The approach that requires the least change
from current practice is to have each project development team "design
with reuse" and "design for reuse." In this approach, the burden is on
each team to recognize the value of reuse and to work accordingly. This
means that teams both take into account what components are available as
they create their designs and build their new modules to be generally
(re)useful wherever possible. In this way, they save development time by
using the working capital built on previous projects and also create new
capital for use in the future.

Such an approach can be supported by an explicit company policy requiring
reuse, with corresponding performance reviews and perhaps financial
rewards for good performance.

The obvious difficulty with this approach is the need for incentives.
While designing with and for reuse benefits the firm as a whole, it can
distract the team from the project at hand. Designing with reuse requires
that teams take the initiative to research the corporate library
effectively and either trust or test what they find there. The simpler,
quicker path, as they see it, may be, in many cases, to build anew. And
designing for reuse can retard the accomplishment of immediate project
goals.

These incentive problems can be addressed, of course, but they must be
addressed for this approach to work well. In addition to designing the
team and incentive structures well, managers must make sure that the
support systems actually support, rather than obstruct, reuse. If certain
basic managerial procedures do not change, the company will receive
little benefit from components.

Independent Reuse Teams

An alternative approach is to create a dedicated reuse team, independent
of the teams building deliverable applications. One variant of this
approach is to have the team fill a kind of reconditioning and
abstracting function. Team members survey the code that is developed in
the firm's various projects and pick out the components that seem most
likely to be useful on other projects. They generalize these to capture
the relevant abstractions, document them carefully, and place them in the
corporate library. This function goes well with the valuable practice of
accumulating metrics of the firm's software development activities; it
may make sense to combine the two functions.

While this kind of structure can assure that reusable assets are created,
it does not seem to generate the sort of corporation-wide reuse mindset
from which the greatest benefits could be derived. Reworking components
into reusable shape may be more costly overall than building them that
way to begin with.

Another variant is to have the reuse team chartered to take the
initiative, assess what the application development teams need, and build
assets accordingly. It would seem wise to tie such a team's compensation
in some way to the value it provides to the development organizations it
builds for. This could be handled by some sort of measurement system or
by internal sale of the reusable assets. If by the latter, the team would
have to provide good value in order to be able to survive.

Integrated Reuse Teams

A third approach (favored by Goldberg for large organizations) is to have
a dedicated reuse team whose members work closely with the various
product development teams. In general, a member of the reuse team serves
on each product development team as the reuse coach. This reuse team both
provides expert knowledge of what is already available in the corporate
library and guides the project teams in their own designing for reuse. In
this way, the reuse team provides close, direct coordination between
producers and users of components. Among the services it provides are
collecting metrics of reuse throughout the company and ensuring that the
components which go into the corporate library conform to standards.

This structure lifts several burdens from the development teams. They do
not have to research component availability on their own; their reuse
team coach provides that special knowledge. They are not simply
instructed to "design for reuse" and left on their own; they have a
specialist's instruction as to how to make their particular modules
reusable.

10 Tasks Development Teams Must Master

However they are structured, development teams will face certain
coordination problems caused by extending the structure of software
production across separate producers and users of components. We draw on
the taxonomy of reuse proposed by Adele Goldberg and Ken Rubin,
consultant to ParcPlace: 10 tasks that are at least implicity involved
whenever components are used.

The tasks are:

* Acquire

* Certify

* Classify

* Store

* Communicate

* Locate

* Retrieve

* Understand

* Use

* Maintain

Task #1: Acquire

There are basically three ways to acquire a component: build it new
yourself, buy it off the shelf, or contract out with someone to build it
for you.

Building code in-house is the best way to get what you need if no one
else has it and you can build it more cheaply than anyone else. But, as
external capabilities in the market increase and communication among
software developers improves, the costs of buying on the outside will
drop relative to the costs of internal development.

Buying components off the shelf can be the fastest acquisition method,
with the advantage of reduced development time, but it is the method with
least control for the buyer. It raises dependability and reliability
issues that we take up below under certification.

A contractual arrangement, whereby one firm arranges with a specialist to
provide what it needs, is, in many cases, a good compromise, providing
the efficiency of using external capabilities along with the control of
contractual supervision. It can be costly if there is not much
competition for the contract.

Where a component's function is uncertain, we would expect to see
relatively more in-house development. Especially in the development of
large systems, the interfaces among modules evolve as the large system
evolves. Unanticipated needs of one module necessitate changes, and these
changes propagate back through the definition of interfaces and require
unanticipated extensions of other modules. Where these kinds of changes
are likely, there is more reason to develop components within the firm.

Task #2: Certify

Perhaps the most obvious challenge facing component technology is the
issue of trust: How is the user of a component built elsewhere, perhaps
even by some anonymous, unreachable engineer, to know that the component
will work? There is a lot of bad, bug-ridden software, and experience has
shown programmers that they should be careful of what they do not know.

The certification challenge is not new with component technology.
Consider software built in the traditional fashion: from scratch for one
project. When such software is built by a team, is there any assurance
that what any given team member provides will work properly? For that
matter, when a programmer working alone builds something for herself,
does she have any guarantee that she has built it right? We perceive the
two settings so differently because we know we can fix a component we
designed ourselves, but we are not so sure we can fix it if someone else
designed it.

But the whole point of certification is to avoid having to fix anything.
The notion that "we can fix our own bugs," while true, is not to the
point, because fixing our own bugs is costly. It may be more costly to
debug our own code than it would be to pay a component supplier to fix a
bug in a component we have bought. With purchased components, we at least
have the recourse of withholding payment. Furthermore, it seems likely
that component suppliers may warranty their software, fixing bugs for
free.

The most straightforward means of certifying components is formal
testing. This seems to be the method favored by corporate reuse projects.
No component is admitted to the corporate library without being properly
tested. While up-front testing entails a large upfront cost, the
investment appears to pay off.

Alternatives to formal certification procedures are more informal,
market-like means of establishing trust. The reputation of the builder
and/or of the component itself is often an important assurance of
quality. We may trust a certain component, for example, because every
other component we have received from its supplier has been error free
and robust, or because previous users have made known their satisfaction
with it.

Tasks #3-7: Classify, Store, Communicate, Locate, Retrieve

Once acquired, components must get to the people who can use them.
Because they are intended for incorporation in a number of projects,
components need to be made readily available to large numbers of
potential users. This is the next main coordination problem of components
markets, and it incorporates Goldberg's and Rubin's next five
elements--classify, store, communicate, locate, and retrieve.

All of these involve coordinating providers and users of components by
enabling knowledge about and access to the components. This combined
category covers processes by which the new capital goods move from one
stage of production to another. It is a communication problem: How can
the availability of components be made known to potential users?

Within firms, the best approach seems to be some combination of a library
of reusable components, a librarian, and possibly a reuse team. Although
much work has been done recently on this approach, our understanding of
it is immature and the challenge is substantial. Again, the core of the
problem seems to be the complexity of software, deriving from the
unlimited range of functionality which it provides. Describing that
functionality so that others may readily learn what a component does is
no easy task.

Classification of components, to facilitate their subsequent location, is
challenging because there are so many dimensions to software. Locating
components is difficult for the same reasons. On top of all these
difficulties is the problem that using components requires changes in the
way software development firms operate--the extensive management changes
that must accompany the development of the new tools.

Hence, we have corresponding technological and management challenges that
will need to be addressed together. Technologically, we need appropriate
library tools that address the multidimensionality of software. At the
same time, we need new development procedures aimed at facilitating use
of the new technologies.

Task #8: Understand

There are at least two different dimensions to understandability which
can be mapped against two categories of components: white box and black
box. White-box components are those whose source code can be read and
(potentially, at least) altered. They can, in principle, be understood by
direct examination. Black-box components, by contrast, hide their inner
workings. Only the public interface is visible to users. To understand
these, users must depend on some external representation such as
documentation or cues in the public interface, as with visual
programming.

Tasks #9 and 10: Use and Maintain

Finally, components must be used and maintained. Most important is that
the users of components must know how to use them. Programmers must be
well-educated in the theory and techniques on which component use
depends. Because the technology is in very early stages, this means that
a very large investment in human capital will be necessary before
component software can take off. Use raises issues of adaptation and
integration.

ADAPTATION. The main coordination challenge in using a component seems to
be getting it right. Where adaptation is necessary, it may be
accomplished by the user or the component provider. If by the user, the
understandability of the code is crucial. Component-providers may assist
with adaptation by offering support, perhaps in the form of advice and
consulting, or perhaps in the form of on-site assistance with the
necessary adaptation.

INTEGRATION. As a system gets larger and more complex, the challenge of
integrating it increases. To meet the challenge, proper encapsulation and
effective communication are of the essence. The difficulty of integration
increases in proportion to the interdependency of the various modules.
Where module designs make many assumptions about the functioning of other
modules, conflicts are likely to be frequent and integration troublesome.
Good encapsulation and small, clear interfaces are therefore important.

Conclusion

Outside Sources Help Software Insiders Understand the Future

The view of the software industry taken in this report is that of
outsiders. We are accustomed to studying markets, identifying the
background conditions in which they flourish, and diagnosing the
pathologies that result from attempts to circumvent them. What we think
we add with this report is a framework for thinking about the software
industry.

The successful expansion of this industry depends on many of the same
factors it depends on in any other industry. If the software industry is
to continue to flourish, it will have to overcome cultural,
institutional, political, legal, and economic obstacles to its expansion,
not only the technical issues with which software engineers are so
preoccupied.

It makes sense, particularly in the case of so young an industry as
software, to draw wherever we can on the rich experience we have
accumulated from the study of other industries. Although there are only a
few scant decades of experience with the software business, mankind has
accumulated hundreds of years of quite illuminating experience with other
industries. Many of these faced the same kinds of challenges in trying to
open up new markets that software is facing. This experience gives us
reason to think that the present problems in the industry are solvable.
-------------------------------------------------------------------------
Topic:     Market Analysis
           Computer Software Industry
           Trends
           Object-Oriented Programming
           Software Engineering
           Hardware
           System Design


Record#:   13 472 300
                              *** End ***
