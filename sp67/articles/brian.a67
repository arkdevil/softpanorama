Title:     Year of the OS: Unix versus Windows NT
Author:    Bryan, John


Abstract:  There are several differences between two of the most powerful
           desktop operating systems (OS), Microsoft Corp's Microsoft
           Windows NT and Unix.  While Windows NT is designed to function
           as a standalone, prioritized multitasking system, most
           versions of Unix are multiuser, time-sharing and multi-tasking
           systems.  Because of the their many powerful elements, both
           OSs require a substantial amount of computing resources to
           reach their potential.  NT is an event-driven system; Unix is
           process-driven.  Event-driven means NT prioritizes processor
           functions by events.  An event is the initiation of a process
           caused by any external signal.  NT is a true graphical
           operating environment, while Unix is character-based.  The two
           main standards on which most Unix packages are based are
           System V Release 4 and OSF/1.  NT probably has the best chance
           of becoming the dominant OS because it is a new system based
           on the best elements of its predecessors.

Last month, we defined the desirable features of a modern operating
system, and compared those features to Windows/DOS, Unix, OS/2, NT, and
System 7.  Our wish list included: system-to-system communications,
transparent application-to-application data exchange, multiple concurrent
applications, a linear memory scheme with application protection, virtual
memory, and support for multiple processors.  When push came to shove,
only two OSs have made it to part two: Unix and NT.  This month, we'll
take apart both operating systems and see just where the real power lies.

THE UNIX AND NT DIFFERENCE

Several fundamental differences exist between Unix, in any form, and
Windows NT.  First, Unix is a multiuser, multitasking, and time-sharing
operating system, while NT is designed primarily as a single-user,
prioritized multitasking OS.  Actually, that is not quite true of NT:
Though it does not support a terminal mode of many users accessing the
same central processor, it does support client/server computing.  The
client is not restricted to using Windows for Workgroups, but may be run
on distributed systems running DOS or Windows, or on a Macintosh or
workstation running Unix.  Both NT and Unix, however, are high-end
operating systems that require a significant commitment in terms of
computing power in order to be effective.

NT borrows a concept from System 7's design that produces a second
functional difference between NT and Unix: NT is an event-driven
operating system.  Unix and DOS, and most other systems, are
process-driven.  An event-driven system prioritizes processor activity by
events--that is, any external stimuli which signals the initiation of a
process.  This consideration has a further-reaching impact than one might
at first think, though the most notable is the priority of the active
window in the graphical environment.

Another conceptual difference is that NT is a truly graphical operating
system, rather than a character-based OS with a graphical interface
pasted on top, as is the case with DOS/Windows and Unix/Motif or Unix
with X Windows.  This produces a distinctly different look and feel in
the manner in which the system handles output and application
responsiveness.  All screen output under NT is handled by the Win32
sub-system, with other application environments translated.  Under Unix,
an application may or may not be supported by the graphical interface,
and many applications will manipulate the screen directly.

UNIX BY FLAVORS

Unix is in a process of unification toward a standard API, or Application
Program Interface, but it isn't there yet.  The vast majority of Unix
flavors fall into one of two versions.  The first is System V Release 4,
or SVR4.  SVR4 is AT&T's version of the complete operating system.  SVR4
brings together most of the functions and systems of AT&T, Berkeley BSD,
and Sun OS releases into a single package standardized under the SVID
(System V Interface Definition) suite of benchmarks.

This other standard of Unix (I hesitate to say "second standard") is
OSF/1.  OSF, the Open Software Foundation, is a consortium of vendors led
by IBM, DEC, and HP, all of whom were concerned about AT&T's agreements
with Sun Microsystems regarding the direction and development of Unix.
The group banded together to push OSF/1, a version of Unix based on the
Mach kernel developed at Carnegie-Mellon University.  The primary
differences between OSF/1 and SVR4 is OSF/1's support, in its standard
configuration, of symmetrical multiprocessing and "threads."

So how does each operating system handle the various functions in its
environment? Let's take a closer look.

THE POWER OF UNIX

Unix had its beginnings in AT&T's development labs over 20 years ago, and
has evolved into today's operating system of choice for a large number of
platform types and processors.  Without going into all of the various
evolutions and permutations, it is sufficient to say that Unix has
arrived in the '90s as a complete, highly functional OS that has been
adapted to the widest range of systems of any operating system.

Unix consists of five major components.  These include the operating
system kernel, the user command interface, Unix commands and utilities,
Unix system services, and the Unix programming interface.  Unix is
unusual in that the user command interface is not an integral part of the
operating system.  It is a separate program, loaded like any other, and
interchangeable.  There are several popular user command systems, among
them the "C" shell and the Bourne shell.  Another modification is the "X"
window, or Motif interface, which gives Unix a graphical element, though
these are not as complete as those found in a system designed from the
"ground up" for a graphical interface.

AT&T's Unix is a monolithic design, meaning that all of the fundamental
portions of the operating system, hardware dependent or otherwise, are
interrelated to one another.  In terms of adaptive system architecture,
this means that Unix is hard to modify for new devices because of the
amount of code that has to be changed.

This is an important point.  Device support is probably the single most
significant problem that any operating system faces in a non-regulated
environment.  By non-regulated, I mean any situation where hardware comes
from a wide variety of vendors, with different system and peripheral
types.  Unix's origins are in the large-system environment, and Unix is
still generally supplied by, and customized to, the hardware vendor.

OSF/1, with its Mach microkernel, has some advantages in this respect.
Microkernel architectures operate on a client/server basis, and device
support and other functions can operate out of user space.  In this
format, the system is protected from crashing in the case of an error in
application code.

The Unix kernel, the heart or core of the operating system, is
responsible for several functions.  Among these are process scheduling,
device management, disk and file management, system calls, and the user
console interface.  These general functions exist throughout the kernel
in several modules.

The innermost layers interact directly with the system hardware, and
perform the basic functions which give Unix its power.  These layers are
generally written with a fair amount of assembly code, which is
non-portable, and means that modifications must be largely written.  At
this level, the operating system also handles process representation,
scheduling, and dispatching.  The process scheduler also handles
synchronization (Unix is, first and foremost, a time-sharing OS) and
interprocess communication.

I/O services are handled by Unix in a unique manner.  Each I/O device is
established as a special file, and is accessed by the Unix file system.
All special files, as opposed to user data files, are kept in the /dev
directory. Even a system's main memory is accessed through a special
file.  Unix file services provide protection for all files in a Unix
system, and the kernel provides special protection for main memory and
the active disk.

Most readers will be familiar with the layout of the Unix file system
because it is the model upon which DOS is based.  The standard Unix
layout, though, contains several directories that are more or less
mandatory to the function of the system.  Besides the root directory,/,
these include the /dev,/usr, /etc,/bin, and /usrs directories.

I've already mentioned that the /dev (for device) directory holds the
special files used for device support.  The /usr directory is where the
system commands and program files are stored, in much the same fashion as
a /dos directory in a DOS system (at least in mine).  /etc contains the
files which maintain information about the user: who is logged on to the
system at any given moment, passwords, etc.  /bin is where utility
programs are commonly kept.  /users may be located under /usr, or may
mounted under /, and is where the individual users store their files
and/or create their own directories.

Again, Unix is designed to be a time-sharing OS, granting every process a
quantum of processor resources in order to maintain equitability of
function for each user.  In the graphical environment, since Unix does
not prioritize the processes associated with running a GUI, as opposed to
disk function or I/O, performance at that interface will frequently
suffer.  It is not uncommon to see individual windows in the "X"
environment wait for a redraw as underlying processes, like a disk seek,
execute.

One of the major problems is defining a "standard" Unix is that everyone
has a version of the operating system ported to their hardware.  Unix, in
one incarnation or another, is available for every 32-bit and most 16-bit
processors ever made.  It has been adapted to the realtime environment,
supercomputer systems, portables, mini- and mainframe installations, and
personal computers.

ENTER NT

While Windows NT is not ported to every processor under the sun, it is
available for systems based on Intel's 386-compatible CPUs, the MIPS
R4000, and the DEC Alpha.  This provides a wide array of system hardware
to choose from, more or less something for everyone.  And where Unix must
have a graphical interface added (in the form of X Windows or Motif), the
GUI of Windows NT is an integral part of the OS, identical in appearance
to the already popular Windows 3.x.

The core of Windows NT is a microkernel, a similar design concept to
Mach, the basis of OSF/1.  A microkernel doesn't necessarily mean that
the complete operating system is small, though, and in this case it
certainly isn't (with all the bells and whistles, the beta release of NT
likes 12Mb or more of RAM).  What a microkernel does for NT is make the
code easily adaptable to any type of 32-bit CPU.  NT's kernel sits atop
the hardware-dependent portion of the operating system, the HAL, or
Hardware Abstraction Layer.  The HAL is what makes each variation of
underlying hardware appear the same to the kernel.

The HAL handles the system bus, the DMA controller, the memory system,
the interrupt controller, and system timers, parceling out resources to
the kernel.  Microsoft has provided a HAL for Intel and compatible
processors, for the MIPS R4000, and for Digital Equipment's Alpha.  All
of these are for uniprocessor machines.  Manufacturers who produce
multiprocessor SMP systems, like the Compaq Systempro, provide their own
HAL for each platform.  The division between HAL and kernel makes this a
much easier task than adapting a Unix system to a customized platform.

Like Unix, the Windows NT environment is divided into two separate modes,
user and kernel.  In the kernel mode space are the system services, a
blanket designation for several kernel functions, the kernel itself, and
the HAL.  The combined kernel and system services are called the NT
Executive.  While system services include many of the same functions
found in the Unix kernel, there are some differences.

The components of the NT Executive are the kernel, the object manager,
the security reference monitor, the process manager, the local procedure
call facility, the virtual memory manager, and the I/O manager, which has
several submodules under the aegis of its control.  Each of these modules
is isolated via an API-like interface that allows modification or
replacement without changes being implemented in adjacent or underlying
modules.

Windows NT is as close to an object-oriented operating system as is
currently available.  Object orientation means that the data that must be
manipulated is formatted as a group of "objects" with a defined set of
characteristics.  This minimizes the amount of software that must be
rewritten in order to encompass a change in data type.  In an operating
system, the "data" that is being manipulated are the components of the
system, files, devices, memory, processes, etc.  The creation,
management, and deletion of these "objects" is handled by NT's object
manager.

The process manager is NT's equivalent of Unix's swapper.  This module
manages the processes and threads of execution that make NT run.  But
where the Unix swapper runs as a continuous background process, the
process manager runs in the context of the executing thread, reducing
operating system overhead.  Actually, as in OSF/1, the implementation of
threads in NT also reduces system overhead, allowing more efficient
operation of the OS.

Because NT supports several different operating subsystems (DOS, POSIX,
OS/2, Win16, and Win32), the virtual memory manager has a rather complex
task in providing protected memory space for all of the simultaneous
potential applications that might be running on the system.  Indeed, each
of the processors currently supported by NT looks at memory in subtly
different ways, so that the VM manager has to manipulate data blocks both
coming and going.

NT's VM manager is able to map up to 4 gigabytes (232 bytes) of memory
space, a not inconsiderable amount.  Two gigabytes of this space are
earmarked for user processes, while two gigabytes are reserved for kernel
processes.  In lieu of actually having this much RAM in one's system, the
VM manager is able to swap "pages" of memory to disk as the physical
memory of the system becomes full.  NT supports page sizes from 4K to
64K, but the default is 4K.  Because NT is a true multitasking OS, VM
manager supports multiple pages associated with multiple threads of
execution, protecting memory space while allowing processes shared
access.

Windows NT is a secure system, meaning that each user must log on to the
system and establish an ID.  This system is managed by the security
reference monitor.  The government's National Computer Security Center
has established several levels of security for computers and operating
systems, from A1 (highest) to D (lowest).  Versions of Unix are
represented at about every level, though the standard implementation is
generally rated at C1 (Discretionary Security).  NT is designed to
provide C2 protection (Controlled System Access), a slightly higher
level.

The security reference monitor maintains this protection in much the same
fashion as Unix security systems, with encrypted passwords, but NT has a
generally higher level of granularity than Unix.  Greater granularity
means that more aspects of more objects are protected, including memory
protection, device protection, and auditing of security-related
activities.  NT is also designed to be easily migrated to the B2
(Structured Protection) level of security, more appropriate for secure
government installations or financial institutions.

The user mode of NT, as opposed to the kernel mode, supports the user
subsystems, which communicate with the Executive via the Local Procedure
Call Facility.  The LPC is a highly optimized version of the
industry-standard RPC (Remote Procedure Call) found in network
environments.  The LPC serves as the interface between the user
subsystems and the executive, translating messages and coordinating the
message traffic.

The messages come from several protected subsystems found in the user
mode section of Windows NT.  Of these subsystems, the Win32 subsystem is
the most significant, for a variety of reasons.  The Win32 subsystem
controls all output to the system display, and receives all output from
the application environments.  There are five environment subsystems in
which applications may be run.  These are Win32, POSIX, OS/2, DOS, and
Win16.  These environments are call "clients."

The Win32, POSIX, and OS/2 environments are full 32-bit APIs.  The DOS
and Win16 APIs run in a VDM, or Virtual DOS Machine, which is supported
by the Win32 subsystem.  There are other subsystems that are not
environments--for instance, the security subsystem and networking support
subsystems.

To reiterate here, Windows NT is a graphical environment, not a graphical
interface running on a character-based system.  It looks like plain old
Windows, but underneath it is a much different breed.  Where Windows is
an application for DOS, both Windows and DOS are applications on NT.

One benefit of having all of the client environments run under the Win32
subsystem is that Win32 provides a translation between APIs for the
various client environments, making communication between applications
possible.  It is also another key of the system so that any may be
modified, updated, or even removed without affecting the rest of the
system.

From the standpoint of migration, the Win16 and DOS subsystems are
especially important to the millions of current users of those systems.
Both of these subsystems run in a VDM.  Because DOS applications are
particularly ill-behaved in a multitasking environment, it is the task of
the VDM to isolate the DOS application and protect other subsystems while
having the DOS app believe that it has control of the environment.  DOS
applications also handle memory in a different manner than NT's flat
32-bit model, and the Win32 subsystem handles the translation from the
segment:offset model to the Windows NT native mode.

THE HARDWARE IT TAKES

Both Unix and Windows NT are high-end operating systems, and the
resources required to run them effectively are significant.  Unix has an
installed base in the workstation environment, where Windows has been
conspicuously absent.  But the popularity of X Windows and Motif has made
it obvious that a graphical interface is a desirable alternative to the
command line for almost any user.  All this aside, a significant
proportion of systems currently in use are not capable of running either
system, Windows NT or Unix with X or Motif.

The vast majority of installed systems in the business environment are
built around the Intel 8086 processor, with a surprising percentage based
on the 80286.  After all, the IBM AT-339 was the single most popular
computer system ever sold, and there are a fair few left running.  But
estimates of the number of PC-compatible systems run as high as 75
million, perhaps more, and even the percentage of these that are
386-based or higher far eclipses the number of RISC- or CISC-based
workstations installed.

The requirements for running either operating system are remarkably
similar.  While Unix has been ported to a number of 16-bit processors, it
isn't really worth running without a 32-bit engine, preferably a fast
one.  NT is 32-bit only; indeed, it is only available on three processor
types, the 386 and compatibles family, the MIPS R4000, and the DEC Alpha.

Microsoft claims that NT is targeted to run on systems with as little as
8Mb of RAM by the time shrink-wrapped software reaches the shelf, though
it certainly hasn't made it there yet.  Unix will run quite handily in
8Mb of space, though the results are better if there is more memory.
100Mb is the minimum recommended disk size for either operating system,
and again, more is better.

The ideal operating system would be able to run on all of the hardware
platforms in the installed base, and would be easily portable to new
hardware as it becomes available.  Unix has this characteristic, but,
unfortunately, it is not a single version of the operating system that
accomplishes the task.  Instead, every major manufacturer has ported a
version of Unix to their systems, and applications are generally not
compatible from one version to the next.

TOMORROW'S DESKTOP

Unix has been around for better than 20 years, and every few years some
pundit says that Unix is "poised to take off" in terms of popularity.
Somehow, though, it still hasn't.  SVR4 is as close to unified API as
Unix has gotten, yet there is some significant competition in the OSF/1
consortium.  Sun Microsystems is the number one provider of
workstation-class systems, but IBM is the number one provider of business
computers.  Of course, the waters are further muddied by IBM's support of
OS/2 on its personal computer line, which could have an impact on NT's
acceptance.  In any case, what really hinders Unix is the lack of
"shrink-wrapped" applications for a single standard operating system.

NT provides application compatibility across platform types, and it
appears to offer enough additional benefits to justify its use as a
primary operating system in just about any environment.  One factor in
the eventual popularity of NT will be the acceptance, by the power-user
crowd, of systems built around the R4000, the Alpha, and Intel's Pentium.
Introduction of these systems should push the price point of 486-based
platforms somewhat lower than they already are, and this could also boost
NT sales.

Microsoft has plans to introduce, in the next couple of years, operating
systems that will enhance the position of NT as the patriarch
(matriarch?) of a Windows "family" of systems, covering systems from
portables to dedicated network, database, and video servers.  Microsoft
will release, sometime in 1993, Win32s, a version of the Windows NT API
that will allow a 32-bit binary to run on a 16-bit Windows 3.1 system,
and a new version of DOS, currently called "Chicago," that will (finally)
break the 64OK barrier of all previous DOS releases.

                              *** End ***
