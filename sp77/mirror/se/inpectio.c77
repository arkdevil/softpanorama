From: sqegelp@aol.com (SQE Gelp)
Newsgroups: comp.software-eng
Subject: Re: Software Inspections
Date: 11 Aug 1995 01:54:03 -0400

>I am curious if anyone has any experience or opinions
>regarding software inspections and the formal "meetings".
>L. Votta at AT&T published an interesting paper at
>SIGSOFT '93, which argues that inspection meetings increase
>cost without increasing efficiency.

The following is comment & opinion:

Consider first that:  (1)  In the article, "all bugs are created equal".
Inspection effectiveness should ** not ** be measured by bug count
statistics, but by dollars of failure impact potential of the defects
detected.  One defect can be worth over a billion dollars (ask AT&T about
Jan. 15th, 1990 and the misplaced Break Statement that brought the network
down for 8 hours -- finding that one bug in a meeting would have funded
quite a few meetings).  On the other hand, many detected bugs may add up
to only a few thousand dollars of impact.  It is obviously harder to
measure impact, but unless impact is uniformly distributed, bug count does
not measure importance.

Had impact potential been measured, Votta still might have found that the
meetings did not find any "critical" defects i.e. pay for themselves.

So next consider that (2) the inspection process described seems to focus
the meeting on the reporting of "already discovered defects".  The search
for additional bugs is secondary (if considered at all).  If this is your
process and you aren't finding any "critical" defects, then the
"Deposition process" Votta proposes is very likely to be a significant
improvement.

But, consider (3) the human factors of the described situation and a
potential lost opportunity.  It is the remaining critical defects (RCDs)
that are important!!!  But this is not the focus of the meetings described
nor indeed most inspection meetings in current practice.  Is it a surprise
that we are not very effective at finding what we are not focussing on???


Finally, consider the opportunity for (4) a different type of meeting.
How about focussing the meeting exclusively on the discovery of RCDs - no
discussion of found bugs except as an explicit method for finding RCDs.

How about assigning one inspector to be a "Guide" and lead the hunt for
the RCDs.  Being an inspector, the Guide would have spent preparation time
analyzing the workproduct, possibly have found some bugs and have some
intuition as to where some RCDs might be hiding.  Prior to the meeting,
the Guide would (a) study the documented results from the other
inspectors, (b) consult with the author, and (c) develop a RCDs search
strategy.  The strategy would be composed of a stack of <analysis method,
workproduct location> pairs.  [Like fishing:  <kind of bait and tackle,
position on the lake>]  The meeting would be driven by this strategy.  If
the first method is yielding results, stick with it.  If not, pop the
stack and move on.  [Note that the Guide is a generalization of Fagan's
"Reader", but is not constrainted to only one group analysis method.]

If this new type of meeting yields one or two more RCDs than your current
approach, you will be glad you tried it.

If you are interested in learning an inspection process that incorporates
this new type of meeting along with other innovations, send E-mail to
sqeinfo@sqe.com

